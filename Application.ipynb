{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"apikey.json\"\n",
    "\n",
    "from google.cloud import vision, texttospeech, translate\n",
    "from google.cloud.vision import types\n",
    "from PIL import Image\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Virtual_Eyes:\n",
    "    \n",
    "    def __init__(self): #analzye_type; resim analizi için 0, yazı tanıma için 1\n",
    "        self.imgAnnotator = vision.ImageAnnotatorClient()\n",
    "        self.translator = translate.Client()\n",
    "        self.textToSpeech = texttospeech.TextToSpeechClient()\n",
    "    \n",
    "    \n",
    "    def take_a_photo(self):\n",
    "        try:\n",
    "            cap = cv.VideoCapture(0) # 0 indexli kameradan görüntü alıyoruz\n",
    "            ret, frame = cap.read() # kamera görüntüsünü alıyoruz\n",
    "            b, g, r = cv.split(frame)\n",
    "            photo = cv.merge([r, g, b]) # bir nevi renklendirme yapıyoruz\n",
    "            cap.release()\n",
    "            \n",
    "            cv.imwrite(os.getcwd() + \"/imgs/takenphoto.jpg\", photo) # resim dosya olarak kaydediliyor\n",
    "            return True # resim çekilip kaydedildi\n",
    "        except:\n",
    "            return False # hata çıktı demektir\n",
    "    \n",
    "    \n",
    "    def make_image_analysis(self):\n",
    "        try:\n",
    "            with io.open(os.getcwd() + \"/imgs/takenphoto.jpg\", 'rb') as image_file:\n",
    "                img = image_file.read()\n",
    "            \n",
    "            image = types.Image(content=img)\n",
    "\n",
    "            list_of_findings = []\n",
    "            response = self.imgAnnotator.label_detection(image=image)\n",
    "            for label in response.label_annotations:\n",
    "                list_of_findings.append(label.description)\n",
    "            \n",
    "            # bulgular İngilizce'dir, Türkçe'ye çevrilmesi için fonksiyon çağırıyoruz\n",
    "            return self.translate_texts(list_of_findings) or None # eğer bulgu yoksa None döndürür\n",
    "        except:\n",
    "            return None # eğer hata varsa None döndürür\n",
    "    \n",
    "    \n",
    "    def make_text_analysis(self):\n",
    "        try:\n",
    "            with io.open(os.getcwd() + \"/imgs/takenphoto.jpg\", 'rb') as image_file:\n",
    "                img = image_file.read()\n",
    "\n",
    "            image = types.Image(content=img)\n",
    "            \n",
    "            list_of_findings = []\n",
    "            response = self.imgAnnotator.text_detection(image=image)\n",
    "            for text in response.text_annotations:\n",
    "                list_of_findings.append(text.description)\n",
    "            \n",
    "            # list_of_findings burada düzeltilmelidir\n",
    "            \n",
    "            return ' '.join(list_of_findings) or None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def translate_texts(self, list_of_texts):\n",
    "        text = ', '.join(list_of_texts)\n",
    "        target = 'tr' # çevirisi yapılacak dil Türkçe için tr\n",
    "        source = 'en' # kaynak dil\n",
    "        \n",
    "        translation = self.translator.translate(text, source_language=source, target_language=target)\n",
    "        return translation['translatedText'] or None # çevrilen yazı cümle olarak çevrilir, eğer yoksa None döner\n",
    "    \n",
    "    \n",
    "    def text_to_speech(self, text):\n",
    "        try:\n",
    "            synthesis_input = texttospeech.types.SynthesisInput(text=text)\n",
    "            voice = texttospeech.types.VoiceSelectionParams(\n",
    "                language_code='tr-TR',\n",
    "                ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL)\n",
    "\n",
    "            audio_config = texttospeech.types.AudioConfig(\n",
    "                audio_encoding=texttospeech.enums.AudioEncoding.MP3)\n",
    "\n",
    "            response = self.textToSpeech.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "\n",
    "            # output.mp3 oluşturulacak dosya\n",
    "            with open(os.getcwd() + \"/speechs/output.mp3\", 'wb') as out:\n",
    "                out.write(response.audio_content)\n",
    "            \n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "    \n",
    "    def display_speech(self, speech):\n",
    "        try:\n",
    "            if speech == \"display_the_speech\":\n",
    "                os.startfile(os.getcwd() + \"/speechs/output.mp3\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    def img_analysis(self):\n",
    "        photo = self.take_a_photo()\n",
    "        \n",
    "        if photo:\n",
    "            findings = self.make_image_analysis()\n",
    "            \n",
    "            if findings:\n",
    "                voiced = self.text_to_speech(findings)\n",
    "                print(findings)\n",
    "                \n",
    "                if voiced:\n",
    "                    self.display_speech(\"display_the_speech\")\n",
    "                    \n",
    "                else:\n",
    "                    self.display_speech(\"error_of_voicing\")\n",
    "            else:\n",
    "                self.display_speech(\"there_is_no_findings\")\n",
    "        else:\n",
    "            self.display_speech(\"photo_could_not_taken\")\n",
    "    \n",
    "    \n",
    "    def text_analysis(self):\n",
    "        photo = self.take_a_photo()\n",
    "        \n",
    "        if photo:\n",
    "            findings = self.make_text_analysis()\n",
    "            \n",
    "            if findings:\n",
    "                voiced = self.text_to_speech(findings)\n",
    "                print(findings)\n",
    "                \n",
    "                if voiced:\n",
    "                    self.display_speech(\"display_the_speech\")\n",
    "                    \n",
    "                else:\n",
    "                    self.display_speech(\"voicing_error\")\n",
    "            else:\n",
    "                self.display_speech(\"there_is_no_text\")\n",
    "        else:\n",
    "            self.display_speech(\"photo_could_not_taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_eyes = Virtual_Eyes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siyah, Karanlık, Beyaz, Gökyüzü, Metin, Yeşil, Kırmızı, Işık, Kahverengi, Yazı Tipi\n"
     ]
    }
   ],
   "source": [
    "virtual_eyes.img_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_eyes.text_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
